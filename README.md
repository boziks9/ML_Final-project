# ML_Final-project: Russian News Topic Classification

Этот проект посвящён автоматической классификации новостных текстов с сайта Lenta.ru по темам с помощью современных методов обработки естественного языка (NLP) и машинного обучения.

**Описание проекта**
Данный проект реализует полный пайплайн обработки и анализа новостных текстов на русском языке. Используется открытый датасет lenta-ru-news.csv, содержащий десятки тысяч новостей с сайта Lenta.ru за разные годы.

Датасет объемный, его можно найти по ссылке на Google Drive: https://drive.google.com/drive/folders/1NsZPv-Tvd9bt66zkDlaDKvIz2R2wvZbz?usp=sharing

**Цель** — построить и сравнить несколько моделей автоматической классификации темы новости по её тексту и заголовку.

**Структура данных**
В датасете представлены следующие столбцы:
1) url — ссылка на новость
2) title — заголовок
3) text — основной текст новости
4) topic — основная тема (класс)
5) tags — дополнительные теги
6) date — дата публикации

**Этапы пайплайна**
1) Загрузка и первичная обработка данных
  - чтение CSV-файла, объединение заголовка и текста.
2) Очистка и нормализация текста
  - приведение к нижнему регистру, удаление ссылок, спецсимволов, лишних пробелов.
3) Лемматизация
  - использование pymorphy3 и razdel для приведения слов к нормальной форме.
4) Удаление стоп-слов и фильтрация пустых строк
5) Построение признаков
  - TF-IDF векторы
  - Word2Vec эмбеддинги
  - BERT (RuBERT) эмбеддинги
6) Обучение моделей
  - логистическая регрессия на разных признаках
7) Оценка качества
  - Accuracy, classification report, матрицы ошибок (confusion matrix)
8) Визуализация
  - матрицы ошибок для всех моделей

**Выводы по результатам**

- TF-IDF + Logistic Regression
  - Лучшая точность (accuracy 0.89) и самые высокие f1-score по большинству классов.
  - Особенно хорошо различает массовые классы ("Россия", "Мир").
  - Для класса "Спорт" — f1-score 0.93, что говорит о ярко выраженной тематической лексике.
  - Класс "Библиотека" не определяется ни одной моделью — это связано с тем, что в тесте всего 1 пример (support=1), и модель не может научиться на таком малом числе примеров.

- Word2Vec + Logistic Regression
  - Чуть уступает TF-IDF по всем показателям (accuracy 0.88, macro avg f1 0.72).
  - Классы "Россия" и "Спорт" определяются почти так же хорошо.
  - Для "Экономика" и "Интернет и СМИ" результаты чуть ниже, чем у TF-IDF.
  - Усреднение эмбеддингов теряет часть информации о структуре текста, что снижает точность.

- BERT (RuBERT) + Logistic Regression
  - Accuracy 0.86 — ниже, чем у TF-IDF и Word2Vec.
  - Для "Мир" и "Россия" f1-score примерно такие же, как у других моделей.
  - Для "Интернет и СМИ" и "Экономика" заметно хуже (f1-score 0.74 и 0.79 соответственно).

Причины: используется только [CLS]-эмбеддинг без дообучения; BERT лучше раскрывает себя при fine-tuning, а не как фиксированный эмбеддер.

**Итог:**
1. TF-IDF остаётся сильнейшей базовой моделью для новостной классификации, особенно когда классы различаются по ключевым словам.
2. Word2Vec — достойная альтернатива, но проигрывает TF-IDF на новостях, где важна частота слов и их сочетания.
3. BERT — не всегда выигрывает "из коробки" на коротких и структурированных текстах без дообучения.

